BASE_TASK_CONFIG_PATH: "configs/tasks/objectnav_hm3d.yaml"
CMD_TRAILING_OPTS: ["TASK_CONFIG.ENVIRONMENT.ITERATOR_OPTIONS.MAX_SCENE_REPEAT_STEPS", "50000"]
ENV_NAME: "SimpleMetaRLEnv"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: []
TENSORBOARD_DIR: "data/checkpoints/good_setup5"
CHECKPOINT_FOLDER: "data/checkpoints/pruebas_iguales_dgx_un_nodo_setup4/ckpt.5.pth"
VIDEO_DIR: "video_dir"
TEST_EPISODE_COUNT: -1
EVAL_CKPT_PATH_DIR: "data/checkpoints/pruebas_iguales_dgx_un_nodo_setup4/ckpt.5.pth"
TRAINER_NAME: "pirlnav-mil"
SENSORS: ["RGB_SENSOR"]
NUM_UPDATES: 100000 # num outer updates
LOG_INTERVAL: 10
WANDB_ENABLED: False
NUM_CHECKPOINTS: 20
# Force PyTorch to be single threaded as
# this improves performance considerably
FORCE_TORCH_SINGLE_THREADED: True

EVAL:
  SPLIT: "val"
  USE_CKPT_CONFIG: False

IL:
  POLICY:
    name: "ObjectNavILMAEPolicy"
  BehaviorCloning:
    encoder_lr: 0.00001 # Outer lr
    lr: 0.00001 # Inner lr
    num_mini_batch: 2 # With this we control how many tasks we have per outer update
  STATE_ENCODER:
    rnn_type: "GRU"

META:
  MIL:
    num_gradient_updates: 2
    num_tasks: 2
    num_updates_per_sampled_tasks: 5

NUM_ENVIRONMENTS: 2

RL:
  SUCCESS_REWARD: 2.5
  SLACK_REWARD: -1e-3
  DDPPO:
    force_distributed: True
    pretrained: False

POLICY:
  CRITIC:
    no_critic: True
  STATE_ENCODER:
    rnn_type: "GRU"
  RGB_ENCODER:
    backbone: resnet18
#    pretrained_encoder: "data/visual_encoders/omnidata_DINO_02.pth"
